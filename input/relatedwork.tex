\section{Related Work}
\label{sec:relatedwork}

\begin{table*}
  \centering
  \input{./input/complexitiestable.tex}
  \caption{\label{table:complexities}Upper-bound ($\mathcal{O}$) on complexities in time, space, and communication of decentralized approaches.}
\end{table*}

%\begin{asparadesc}

% \item[Centralized] collaborative editors constitute an easy way to ensure
%   documents eventually consistent. Until recently, they suited very well the web
%   context since browsers were limited to the traditionnal client-server
%   paradigm. Therefore, there exist a plethora of these centralized editors
%   (e.g. Google Docs, Etherpad, Apache Wave).  Nevertheless, the topology itself
%   suffers issues in privacy, censorship, and economic intelligence.  Indeed,
%   since all communications transit a server, the owner of the latter is able to
%   intercept and use the information without the users' consent (\TODO{REF}).
%   Additionally, centralized solution lacks of scalability and ease of
%   deployment. People who wants to build their own document provider must set a
%   server and carefully check the latter's capacity to hold the load of users
%   (\TODO{REF}).  Finally, users must agree to restriction in terms of service.
%   For instance, Google Docs restricts the writing access of its documents to 50
%   users simultaneously. Beyond, the users are readers (\TODO{REF}). \TODO{Such
%     limitations preclude the existence of crowd edited documents which could be
%     useful in educational cases.}
% \item[Decentralized] collaborative editors are uncommon comparatively. Yet, the
%   appearance of peer-to-peer connections from browser-to-browser opens the field
%   to such editors which become directly accessible in end-user web
%   browsers. Consequently, they are as practicable as centralized web editors and
%   solve all the latter's aforementioned issues except the scalability. Indeed,
%   with such topology, the algorithms and data structures are rethought to handle
%   the operations arriving disorderly.  To insert a character in a shared
%   document, one cannot just use the standard well-known operation \emph{insert
%     element at index} of arrays and expect guaranties on convergence. For
%   instance, if two users concurrently edit a sequence ERTY: the first user
%   inserts a Q at index 0, while the second user inserts a W at index 0. They
%   respectively obtains QERTY and WERTY as resulting sequence. On receipt of each
%   other's operation they respectively obtain WQERTY and QWERTY. Hence the need
%   to inspect these concurrent cases to ensure convergent replicas.  Many
%   approaches have been proposed with the challenging task to find a good
%   compromise between complexities in time, space, and communication.
% \end{asparadesc}

Real-time distributed collaborative editors consider $n$ sites
hosting a copy of a shared sequence of characters. Each site can
update locally its copy immediately without locking by applying an
insert or delete operation. Next, operations are broadcast to others
sites to be re-executed. The broadcast system has to ensure eventual
delivery of operation. Finally, The whole system is correct if it, at
least, converges i.e. when system is idle, all copies are
identicals~\cite{bailis2013eventual}. A correct system has also to
ensure intentions i.e. effects observed at generation time should be
re-observed at re-execution time whatever concurrent
operation~\cite{sun1998achieving}.

A distributed real-time editor is characterized by several
complexities:
\begin{itemize}
\item Generation time: complexity to generate locally an operation
\item Integration time: complexity to re-execute a remote operation
\item Space complexity: complexity to store local copy of the shared
  sequence, state descriptors and logs, if any.
\item Communication complexity: amount of bytes exchanged on the
  network by participants. 
\end{itemize}

Addressing the scalabilty issue require to find a good trade-off
between communication, space and time complexities. First, to be
scalable, communication complexity of decentralized editors has to be
sublinear to the number of participants. In the best case, if we have
$n$ participants, sending a typed character to others requires to
contact $log(n)$ participants. But consistency maintenance of
real-time editors requires to piggy back to each message extra
informations that impact greatly the whole communication complexity.

\begin{asparadesc}

\item [Operational transformation (OT)] allows to build centralized or
  decentralized real-time editors. In OT, operations are generated in
  constant time. Next, an operation has to be transformed according to
  concurrent operations defined on the same state. Consistency is
  obtained thanks to an OT integration algorithm such as COT or SOCT2
  and properties on transformation functions. The Integration time
  complexity depends of concurrency and can be different according to
  different trade-off. In COT~\cite{sun2009contextbased}, time
  complexity of integration is exponential. It can be reduced to
  linear at the cost of high space complexity. In
  SOCT2~\cite{Vidot00}, it is quadratic. Whatever the trade-off chosen
  in the integration algorithm, OT has to transform incoming
  operations according to concurrent operations and a state vector is
  the minimal structure that allows to detect
  concurrency~\cite{charronbost1991concerning}. Hence, OT requires to
  piggy back to operations sent on the network a structure at least
  linear to the number of participants. On space complexity, OT keeps
  the document as a non-collaborative editor can do, plus a log of
  operations. In the worst case i.e. a site is not responding, the
  size of the this log includes all the operations produced from the
  beginning of editing session, where each operation is decorated with
  state vector proportional to number of participants. If average
  case, a garbage collecting algorithm can drop operations integrated
  by all participants. So, the slower participant will determine the
  size of log hosted by all participant. OT is a powerfull approach
  for small groups, performances degrade when the group is growing.

\item [Conflict-free replicated data types] (CRDTs) for sequences
  constitute the latter approaches which solve the concurrent cases by
  providing commutative and idempotent operations. Commutativity of
  operations ensures the correctness of the system. These approaches
  provide commutativity by associating a unique and immutable
  identifier to each element. Defining a total order among the
  identifiers allows retrieving the sequence. Compared to OT, CRDT
  approaches will increase the generation time complexity but do not
  require to detect concurrency at integration time. Hence, CRDT can
  acheive logarithmic integration time that does not depend of
  concurrency. Moreover, as an operation is generated once and
  re-executed many times, CRDT provides an interesting trade-off. On
  space complexity, each element of a shared document will be
  decorated with a CRDT identifier. On the other hand, no log is
  required. Finally, on communication complexity, as CRDT do not require to
  detect concurrency, only the identifier of the element is
  piggy-backed. The size of this identifier determine the
  communication complexity.

  There exist two class of CRDTs for sequences exposing different
  tradeoff.
\item [Tombstone-based] CRDTs such as WOOT\cite{oster2006data}
  associate a constant size identifier to each element but whose
  removals of elements only hide them to the users. Therefore, removed
  elements keep consumming space and the document will grow
  infinitely. Removing detroyed elements requires to run a costly
  consensus algorithm (\emph{does everyone see the removal and agree
    on definitely throw out the element}) which is prohibitevely
  costly and does not scale in number of users, especially in network
  subject to churn (where members join and leave the network
  frequently and freely).

\item [Variable-size identifiers] CRDTs whose removals truely destroy
  the targeted elements but whose identifiers are allocated with
  different size at generation. In these approaches, the allocation
  function is crucial to maintain identifiers under acceptable
  boundaries. Unfortunately, they depend of the insert position of
  elements. For instance, writing the sequence QWERTY left-to-right
  allocates the identifiers [1] to Q, [2] to W, [3] to E, \ldots, [6]
  to Y. But with an identical strategy, writing the same sequence
  right-to-left allocates the identifiers [1] to Y, [1.1] to T,
  [1.1.1] to R, \ldots As we observe, depending on the editing
  behaviour, the identifiers can grow quickly.  If the worst case
  happens, then a costly distributed consensus is required to
  rebalance identifiers as in~\cite{zawirskiasynchronous}.

Finally, the LSEQ algorithm [11] aims to avoid consensus by bounding
variable- size identifiers to a space complexity sublinear to the size
of shared document. It conjectured that identifiers can be bounded to
the $log(s)^2$ where s is the size of shared document. In this paper,
we demonstrate in which conditions  this upper-bound can be proved.

\end{asparadesc}

Table~\ref{table:complexities} shows the upper-bound ($\mathcal{O}$)
of complexities in space, time, and communication of decentralized
approaches. In this table, we can see that both operationnal
transformations approaches, namely SOCT2/TTF and COT-DO, do not scale
in communication since they send messages that grows linearly compared
to the number of writers. Conversely, the representatives of
tombstone-based CRDTs (WOOT, WOOT, WOOTH, RGA, SW, PPS, Neil)
communication complexity only depends of the dissemination protocol
(in logarithm of the number of replicas), however their space and time
complexities include the removals. In other terms, these approaches
are monotonically growing structure, hence, they do not scale in
number of operations performed on the document. The variable-size
identifiers CRDTs comprise Treedoc, Logoot, and \LSEQ. Their
complexities depend of insert positions (or editing behaviour) of the
elements. Treedoc, as a hybrid solution, uses tombstones and suffers
of the aforementionned issue. Like Logoot, it mainly targets monotonic
editing at the end of the sequence. Unfortunately, when the editing
behaviour does not comply with this assumption, the space complexity
grows quadratically. \LSEQ provides a sublinear upper-bound on its
space complexity. Thus, it scales in document size, and
communications. Yet, it requires a local causality tracking mechanism
increasing linearly compared to the number of
writers. \TODO{cf. proposal?}.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../paper"
%%% End: 
