

\section{LSeq: a polylogarithmic path allocator}
\label{sec:proposal}

\LSEQ (polyLogarithmic SEQuence) is the name of the proposed allocation
function. Any sequence data structure using variable-size identifiers can use
it. Our prior works~\cite{nedelec2013concurrency, nedelec2013lseq} empirically
showed that \LSEQ provides a sublinear upper bound on its identifiers' space
complexity. Nevertheless, we did not provide any complexity analysis to support
these observations. In this section we prove the polylogarithmic growth of
\LSEQ's identifiers and state the conditions upon which it applies. The
complexity analysis also includes the space complexity of the replicated
structure, and the time complexity of operations provided by this structure.

\LSEQ improves the identifiers' space complexity by degrading its worst case
complexity. However, the worst case is made non-trivial. If a malicious user
tries to produce the worst case scenario, other editors can detect her easily,
for there is a large difference between the expected space complexity and the
worst case space complexity.

This section starts by describing the allocation strategy. Then, it provides its
complexity analysis.

\subsection{Allocation of paths}
\label{subsec:lseqallocation}

Function \textsc{allocPath} chooses the path associated with each element in
order to encode its relative position with regard to its adjacent elements in
the sequence. For the sake of performance, it aims to keep the underlying tree
with a small depth.

\begin{algorithm}
\input{input/allocpathalgo.tex}
\caption{\label{algo:allocpath}Allocation of paths}
\end{algorithm}

Algorithm~\ref{algo:allocpath} shows the instructions of \LSEQ. First,
\textsc{allocPath} processes the distance between the two paths in order to
retrieve the smallest level of the tree that contains enough room for the new
element.

Then, a \emph{hash function} $h$ defers the path allocation to a \emph{sub-allocation
function} depending on the depth found for the new path. The hash function of
every participant must give identical results~\cite{nedelec2013concurrency}.
% A hidden seed within the replicated document initializes it, for that all
% participants must make identical choices~\cite{nedelec2013concurrency}.
The choices between the sub-allocation functions must follow a uniform
distribution, for we have no knowledge about the future editing behaviors, and
we do not want to favor any.

\LSEQ uses two sub-allocation functions. Indeed, contrarily to state-of-the-art
approaches, \LSEQ uses an \emph{exponential
  tree}~\cite{andersson1996faster,andersson2007dynamic}. Such tree allows each
node to have twice as much children as its parents. Regarding the formalization
of Section~\ref{sec:preliminaries}, it means a restriction over
$\mathcal{P}$. The path is no longer a sequence of natural numbers but a
sequence of number chosen among a subset of $\mathbb{N}$, the size of which is
doubled at each concatenation. For instance, let the path
[$\ell_1.\ell_2\ldots\ell_e$] with $\ell_1\in\mathbb{N}_{<2}$, then
$\ell_2\in \mathbb{N}_{<4}$, and $\ell_{e}\in\mathbb{N}_{<2^e}$. Compared to
constant arity trees, paths require an additional bit per concatenation, for the
subset are growing over depths. The binary size of a path is
$\textstyle\sum\nolimits_{i=1}^{e}\log_2{2^i}=\sum\nolimits_{i=1}^{e}i=
{e^2-e\over{2}}$.
Such growth forbids the existence of trivial editing behaviors leading to the
worst case allocation (e.g. Figure~\ref{fig:allocpathexample}).

Since one allocation function is not enough to characterize efficiently any
editing behavior, \LSEQ uses two functions with antagonist designs in order to
settle each other's weaknesses. Line~\ref{line:lefttoright} shows the
sub-allocation function that targets left-to-right editing behaviors such as the
one used in Figure~\ref{fig:allocpathexample}. Line~\ref{line:righttoleft} shows
the other one that targets the right-to-left editing behaviors. These
sub-allocation functions operates very similarly, for the former chooses the
path starting from the preceding path and adds a small random value while the
latter chooses a path starting from the following path and subtracts a small
random value. They aim to leave more space for future insertions in queue and in
front of the new path, respectively.  When one of these sub-allocation function
do not manage to provide small-sized paths, the other quickly takes the lead. In
such case, \LSEQ must be efficient enough to compensate the loss due to its
unsuitable choice of sub-allocation function.


% These sub-allocation functions work similarly:
% \begin{inparaenum}[(i)]
% \item Get the depth and the interval of the new path to allocate.
% \item Limit the range within the level for the allocation of the new path. A
%   small number of paths are left available inbetween elements to provide more
%   flexibility in regards to spellchecking.
% \item However, while \textsc{left-to-right} uses the previous path and adds a
%   random value within the processed range, \textsc{right-to-left} uses the next
%   path and subtracts a random value within the processed range. In turns,
%   \textsc{left-to-right} allocates a branch closer to the previous path while
%   \textsc{right-to-left} does the opposite, respectively leaving more space for
%   future insertions in queue and in front of the newly inserted element.
% \end{inparaenum}

%%%%%%%%%%

% The function \textsc{allocPath} chooses the path associated with each element in
% order to encode its relative position with regard to its adjacent elements in
% the sequence. For the sake of performance, it aims to keep the underlying tree
% with a small depth. 


% It comprises 3 components. Each of these components fails to provide an
% efficient allocation function. Nevertheless, their composition allows to get the
% best of each by canceling their respective deficiency.



% Combining the three components provides identifiers with a sub-linear average
% size compared to the number of insertions performed which makes it well-suited
% for text editing, and consequently, for distributed collaborative editing.

% The total order $<_{\mathcal{P}}$ is similar to the lexicographic order. We
% define it as $\forall p_j,\,p_k\in\mathcal{P}$ with $|p_j|=j$, $|p_k|=k$. There
% exists an index $0\leq l\leq min(|p_j|,|p_k|)$ such that $p_j = X.Y$ and
% $p_k = X.Z$ with $X\subset \{\mathbb{N}\}^l$, $Y \subset \{\mathbb{N}\}^{j-l}$,
% $Z \subset \{\mathbb{N}\}^{k-l}$. Finally, $p_j<_{\mathcal{P}}p_k$ iff
% $Y[1]<Z[1]$.


%% The unexplicit function $subPath$ returns a truncated path from the root to the
%% depth passed as argument.

\begin{figure}
  \centering
  \subfloat[Left-to-right case with \LSEQ.]
  [Left-to-right editing behavior.]
  {\input{input/lseqtreeexampleA.tex}}
  \subfloat[Right-to-left case with \LSEQ.]
  [Right-to-left editing behavior.]
  {\input{input/lseqtreeexampleB.tex}}
  \caption{\label{fig:lseqtreeexample} Example of \LSEQ's exponential trees with
    two antagonist editing behaviors to create the sequence of characters
    QWERTY. Contrarily to the example of Figure~\ref{fig:allocpathexample}, the
    depth of trees does not grow linearly.}
\end{figure}


Similarly to the example of Figure~\ref{fig:allocpathexample} the example given
in Figure~\ref{fig:lseqtreeexample} depicts the resulting trees after two
antagonist scenarios creating the sequence QWERTY
\begin{inparaenum}[(i)]
\item the left-to-right insertions sequence [($\text{Q},\,0$), ($\text{W},\,1$),
  \ldots] and
\item the right-to-left insertions sequence [($\text{Y},\,0$), ($\text{T},\,0$),
  \ldots].
\end{inparaenum}
In both cases, the exponential tree of \LSEQ starts with a maximum arity $32$
and doubles it at each level. Also, it uses the left-to-right and right-to-left
sub-allocation functions at the first and the second level of the tree
respectively. Since the first level of the tree uses the function designed for
left-to-right editing, the scenario involving the left-to-right editing sequence
results in a tree of depth 1. On the other hand -- and contrarily to the
allocation function presented in Figure~\ref{fig:allocpathexample} -- the
antagonist scenario only leads to a tree of depth 2. Indeed, the identifiers of
\LSEQ quickly reach a level of the tree where the sub-allocation function is
designed to handle the right-to-left editing behavior. If such editing behavior
continues, the new allocated paths will compensate the loss of the first level.

% \begin{asparadesc}
% \item [The function allocDis] creates the di\-sam\-bi\-gua\-tors which have two
%   goals.  It ensures the uniqueness of the triples, even in presence of
%   concurrency and it guarantees that triples can always be inserted between two
%   other triples even when the paths of the latter are identical. The example of
%   Figure~\ref{fig:allocpathexample} illustrates the need of comparisons that
%   preserve the order given by the paths and also examines the
%   disambiguators. During the editing session, the insertion between the
%   elements $W$ and $T$ resulted in an identical path [$29$]. Therefore, without
%   $allocDis$, the order among $W$ and $T$ is ambiguous, and inserting between
%   them becomes impossible. Indeed, if any path [$29.X$] is greater than [$29$],
%   the newly inserted elements will always end up after the $W$ and $T$ in the
%   sequence. Consequently, the disambiguators are necessary to build an
%   allocation function for sequences.
% \end{asparadesc}

% A disambiguator is a list of pairs
% $\langle source,\, clock\rangle$. Similarly
% to the tree of paths, the set of all disambiguators can be represented as a
% tree equipped with a lexicographic total order
% $(\mathcal{D},\, <_{\mathcal{D}})$. While the total order $<_{\mathcal{P}}$
% ultimately compares two numbers, the total order $<_{\mathcal{D}}$ compares two
% pairs. With the same notation than $allocPath$, let $\langle s_1,\, c_1\rangle$
% and $\langle s_2,\,c_2\rangle$ be the $l+1$ couples of the disambiguators $d_j$
% and $d_k$ respectively. $d_j <_{\mathcal{D}}d_k$ iff $s_1 < s_2$, or if
% $s_1=s_2$, $c_1 < c_2$.

% \begin{algorithm}
%   \input{input/allocdesalgo.tex}
%   \caption{\label{algo:allocdis}The function $allocDis$ of \LSEQ}
% \end{algorithm}

% Algorithm~\ref{algo:allocdis} describes the allocation of a disambiguator which
% preserves the intention of the peer that performed the insertion. Identically
% to Lamport timestamps, it uses a unique site identifier and a monotonically
% increasing counter. Basically, it copies the disambiguator of its neighbours at
% the depth where they are equal, and, if none is equal, it copies its own site
% and counter. The latter case happens at least once per insertion which
% guarantees the uniqueness of each identifier. The space complexity of
% disambiguator is upper-bounded by the length of the new path. Furthermore,
% depending on the scenario, it can be drastically compressed.

% Let us go back to the example in Figure~\ref{fig:treemodelexample}. In this
% tree, collaborator $p_1$ inserts the character $R$ between the two pairs
% $\langle [3],\, E\rangle$ and $\langle [4],\, T\rangle$. The resulting path is
% $[3.1]$. Now, we add the disambiguators $\delta_E = [\langle 2,\,1\rangle]$
% meaning that it is the first insertion of collaborator $p_2$, and
% $\delta_T = [\langle 3,\,1\rangle]$ meaning that it is the first insertion of
% collaborator $p_3$. The resulting path associated with $R$ is $[3.1]$. Since the
% first integer of the path of $R$ is similar to the path of the character $E$,
% the algorithm copies the first part of $\delta_E$. Then, since none of the
% adjacent pairs have a length of $2$, the algorithm copies the values of $p_1$,
% i.e. $\langle 1,\,1\rangle$. The resulting disambiguator is
% $[\langle 2,\,1\rangle,\, \langle 1,\,1\rangle]$. This way, $p_1$ inserts a new
% character between $E$ and $R$. As we get the path $[3.0.X]$, the resulting
% disambiguator is
% $[\langle 2,\,1\rangle,\,\langle 1,\,2\rangle,\,\langle 1,\,2\rangle]$.

% \begin{asparadesc}
% \item [The global total order] $(\mathcal{I}, <_{\mathcal{I}})$ is a composition of the
% aforementioned sets $\mathcal{P}$ and $\mathcal{D}$, and their respective total
% orders $(\mathcal{P},\, <_{\mathcal{P}})$ and
% $(\mathcal{D},\, <_{\mathcal{D}})$.
% \end{asparadesc}

% The global total order is defined as:
% $\forall p,\,q \in \mathcal{I}, p<q \Leftrightarrow \exists i$ with
% $\forall_{k=0}^{i-1}, \, p.P(k) = q.P(k) \wedge p.D(k) = q.D(k)$ such that
% $\exists j=i+1$ with
% $p.P(j) < q.P(j) \vee (p.P(j) = q.P(j) \wedge p.D(j) < q.D(j))$.

\subsection{Complexity analysis}
\label{subsec:complexity}

In text editing, most of the editing behaviors can be empirically summarized
as a composition of two basic editing behaviors.
\begin{inparaenum}[(i)]
\item The random editing behavior where the author inserts new elements at what
  appears random positions in the sequence. For instance, this behavior mostly
  arises when syntactic corrections are performed, e.g. the author writes QWETY
  and realizes that the R is missing. She adds the missing character in a second
  time.
\item The monotonic editing behavior where the author repeatedly inserts new
  elements between the last inserted element and an adjacent element (after or
  before exclusively). For instance, when an author writes QWERTY, she generally
  starts from the first character Q to the last letter of the word Y. On the
  opposite, insertions in a logfile are usually performed at the beginning for
  practical reasons. This behavior characterizes both left-to-right and
  right-to-left editing.
\end{inparaenum}

As a consequence, we focus on the space complexity analysis of \LSEQ to random
and monotonic editing behaviors to which we add a worst case complexity
analysis. It is worth noting that monotonic editing behavior represents an
unfavorable case since it tends to unbalance the underlying tree storing the
replicated sequence. As soon as the participants start to edit at different
positions -- which is closer from a real-life use case -- the tree becomes more
balanced and operations become more efficient proportionally. Also, the
analysis does not include an average case since it requires to know the average
distribution of the position of edits performed by a human collaborator which is
obviously very complex.

%% Also, since the space complexity of disambiguators provided by $allocDis$ is
%% upper bounded by the paths allocated by $allocPath$, the space complexity
%% analysis of the path is reduced to the space complexity of the identifiers of
%% \LSEQ.

\subsubsection{Space complexity}

We distinguish the space complexity of each identifier from the space complexity
of the tree. The former being important since it directly impacts the
communication complexity, for that each identifier is broadcast to all
participants; The latter being important since it represents the replicated
document stored locally by each participant.

As stated in Section~\ref{subsec:lseqallocation}, paths require 1 additional
bit per concatenation. In turns, paths require $\mathcal{O}(e^2)$ bits to
encode, where $e$ is the depth of the element in the tree. Fortunately, the
depth is upper-bounded depending on the editing behavior that filled the
exponential tree.

The random editing behavior fills the tree at random. As consequence, the tree
becomes balanced. Being exponential, the tree stores
$\textstyle\sum\nolimits_{i=1}^{k}{2^{(i^2-i)/2}}$ elements, where $k$ is the
depth of the tree. Thus, the depth of paths is upper-bounded by
$\mathcal{O}(\sqrt{\log I})$ concatenations, where $I$ is the number of
insertions. Since paths require $\mathcal{O}(e^2)$ bits to encode, paths have an
optimal logarithmic space complexity $\mathcal{O}(\log I)$. This result applies
to all variable-size identifier allocators~\cite{preguica2009commutative,
  weiss2009logoot}. However, since \LSEQ uses a tree structure factorizing
common parts of identifiers, the overall space complexity is not the sum of
identifiers but only $\mathcal{O}(I\log I)$.

The monotonic editing behavior fills only one branch of the tree. Yet, since the
maximum arity grows over depths, the tree tends to slow down its growth over
insertions. The tree stores up till $2^{e+1}-1$ elements, where $e$ is the depth
of the tree. Hence, the number of concatenation composing a path is
$\mathcal{O}(\log I)$, where $I$ is the number of insertions. Once again, since
the binary representation of paths increases quadratically, the space complexity
of paths taken individually is upper-bounded by $\mathcal{O}((\log I)^2)$.
Overall, the space complexity of the tree remains upper-bounded by
$\mathcal{O}(I\log I)$.

In the worst case, each insertion increases the depth of the tree. Thus, after
$I$ insertions, the tree comprises $e$ elements, where $e$ is the depth of the
tree. The space complexity of paths grows quadratically $\mathcal{I}^2$ and each
new allocated path contains the full tree. Thus, the overall space complexity of
the tree is $\mathcal{O}(I^2)$ too.

\begin{table}
  \caption{\label{table:lseqspace}
    Upper bounds on space complexity of \LSEQ, Logoot and Treedoc. Where
    $I$ is the number of insertions performed on the replicated sequence.}
  \centering
  \input{input/lseqspacetable.tex}
\end{table}

Table~\ref{table:lseqspace} summarizes the space complexity of \LSEQ. In
particular, the expected growth of identifiers is bounded between an optimal
logarithm and a polylogarithm, hence, a sub-linear upper bound compared to the
number of insertions. To provide such improvement, \LSEQ sacrifices on its worst
case complexity that becomes quadratic. However, this worst case is made
difficult to produce, for the two sub-allocations functions with antagonist
designs settle each other's deficiency. Furthermore, if a malicious user tries
to produce the worst case, the difference in complexity makes it easy to detect,
hence, to handle. Table~\ref{table:lseqspace} also shows that compared to
state-of-the-art, \LSEQ significantly improves the identifiers size but exposes
a small overhead on the full structure, i.e. from $\mathcal{O}(I)$ to
$\mathcal{O}(I\log I)$. The tradeoff is beneficial since communications inherit
from the improvement.

\subsubsection{Time complexity}
\label{subsubsec:time}

Time complexity provides insights about the performance evolution of each
operation over insertions. They are divided between their local execution and
their remote integration.  Similarly to the space complexity, the analysis
focuses on three editing behaviors that filled the tree structure: random,
monotonic, and worst case.

The local insert operation simply consists in building a new path according to
two adjacent paths. Therefore, it depends of the depths of the latter which grow
depending on the editing behavior. Since the random, the monotonic, and the
worst case editing behaviors respectively lead to a depth growth upper-bounded
by $\mathcal{O}(\sqrt{\log I})$, $\mathcal{O}(\log I)$ and $\mathcal{O}(I)$, the
time complexity of the local part of the insert operation follows:
$\mathcal{O}(\sqrt{\log I})$, $\mathcal{O}(\log I)$ and $\mathcal{O}(I)$.

The local delete operation simply broadcasts the identifier of the element to
remove to all participants. Hence, whatever the editing behavior, the time
complexity is constant $\mathcal{O}(1)$.

Both the remote insert and delete operations perform the same instructions to
integrate the received result. Consequently, they have an identical time
complexity. Random, monotonic, and worst case editing behaviors respectively lead
to $\mathcal{O}(\sqrt{\log I})$, $\mathcal{O}(\log I)$ and $\mathcal{O}(I)$
levels in the exponential tree structure. Since children of each node are
ordered by path, we perform binary searches recursively until the right leaf is
found -- the delete operation removes the nodes it explores iff the latter does
not have at least another element inside its children. The complexity of one
binary search depends of the level $l$ at which it is performed:
$\mathcal{O}(\log 2^l)$. The repeated binary searches lead to an upper bound of
$\mathcal{O}(\textstyle\sum\nolimits_{i=1}^{e}(\log 2^i))$, where $e$ is the
depth of the tree. Replacing the depth $e$, upper bounds on time complexity are
$\mathcal{O}(\log I + \sqrt{log I})$, $\mathcal{O}((\log I)^2+\log I)$, and
$\mathcal{O}(I)$ for random, monotonic, and worst case editing behaviors
respectively. In the worst case, the algorithms perform one comparison per
element, i.e. per level, in the tree until they reach the deepest leaf.


\begin{table}
  \caption{\label{table:lseqtime}
    Upper bounds on time complexity of \LSEQ. Where $I$ is the number of 
    insertions performed on the replicated sequence.}
  \centering
  \input{input/lseqtimetable.tex}
\end{table}

To interface the user's view of the document with the underlying replicated
sequence, an additional lookup operation is necessary. Its goal is to retrieve
the identifier of the element at the specified index in the sequence, and
converse. Since the structure is a tree, this access is not direct.

To consistently manage the translation between sequence structure and the tree
structure, the latter stores with each node the number of elements included in
its sub-trees. Each insertion and removal updates these counters as they explore
a path. Then, processing an index comes down to count the number of elements in
the siblings of explored nodes starting from the beginning or the end of the
sequence. Unfortunately, it can be costly depending on the editing behavior that
filled the tree.

The random editing behavior leads to an exponential tree of depth bounded by
$\mathcal{O}(\sqrt{\log I})$. In such case, a very small portion of the whole
tree will be explored. The upper bound happens when the explored nodes are
exactly in the middle of its siblings, for it forces to check at least half of
these sibling per depth. Since each node stores twice as much children as its
parents. The number of siblings to check doubles at each depth. Overall, the sum
of these siblings is equal to the number of node at the deepest level, which is
$\mathcal{O}(2^{\sqrt{\log I}})$ elements. 

From an identical reasoning, the lookup operation after monotonic editing --
which also constitutes the worst case for this operation -- is upper-bounded by
$\mathcal{O}(I)$. Indeed, only one branch is filled and explored. The counters
become useless since all nodes but one have only one child. The exploration
directly ends up in the deepest level containing $\mathcal{O}(2^{\log_2 I})$
elements where half of them must be checked leading to
$\mathcal{O}(I)$.

\begin{table}
  \caption{\label{table:lseqlookup}
    Upper bounds on time complexity of the lookup on a \LSEQ structure.
    Where $I$ is the number of insertions performed on the replicated sequence.}
  \centering
  \input{input/lseqlookuptable.tex}
\end{table}

Table~\ref{table:lseqtime} and Table~\ref{table:lseqlookup} summarize the time
complexity of operations. The exponential tree structure leads to efficient
update operations. Its drawback lies in the lookup operation making the link
between the view and the replica. In particular, monotonic editing leads to the
worst case scenario where the access grows linearly. Fortunately,
\begin{inparaenum}[(i)]
\item the view should not be updated if the index of the change falls outside
  the user's visibility window. Thus, the lookup can stop earlier if it explores
  the tree outside the scope;
\item keeping fast accesses to the newest path and its adjacent paths removes
  the cost of the lookup, for the repeated insertions -- if monotonic -- alone
  can maintain these fast accesses up-to-date.
\end{inparaenum}

\subsubsection{Summary}

The complexity analysis reveals the improvements brought by \LSEQ as well as
their cost.  \LSEQ sacrifices on its worst case complexity to improve on other
editing behaviors that are considered likely in collaborative editing. The most
important result is the polylogarithmic space complexity of identifiers, for it
applies on communication complexity. In comparison, state-of-the-art
allocators~\cite{preguica2009commutative, weiss2009logoot} only provided
linearly upper-bounded identifiers. Other analysis such as the local space
consumed by the replicated structure, and the time complexity of provided
operations shows that the tree as replicated structure is
efficient. Nonetheless, based on preferences, one could choose an array -- as a
flat version of the tree -- to improve the performance of operations at the cost
of increased memory usage~\cite{weiss2009logoot}.  Section~\ref{sec:experiments}
validates our complexity analysis on experiments. The next section describes the
other components necessary to build a decentralized collaborative editor that
scales.


% The space complexity analysis reveals that the allocation function \LSEQ
% sacrifices on the worst-case space complexity to improve the space complexity of
% the monotonic editing behaviours. Nevertheless, in text editing, the worst-case
% happens with a very low probability compared the other cases. Furthermore, it is
% worth noting that usually, the authors do not write a document in a single
% round, starting from the beginning to go straight up to the end (as the
% monotonic analysis could suggest). On the contrary, the authors write sections,
% structure the documents, perform corrections, rewrite parts of the document,
% reorganize, etc. This behavior (between random and monotonic behavior) tends to
% even up the branches of the underlying tree of \LSEQ. In the case of random
% editing, the space complexity is asymptotically optimal $O(log\,n)$ while it is
% very interesting in a ``normal setting'' $O((log\,n)^2)$.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../paper"
%%% End: 