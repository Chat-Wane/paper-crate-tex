
\section{CRATE}
\label{sec:proposal}

\CRATE (stands for CollaboRATive Editor) is a distributed and decentralized
collaborative editor running directly inside web browsers.
Figure~\ref{fig:architecture} depicts \CRATE's architecture with four layers:
\begin{inparaenum}[(i)]
\item communication: includes the editing session membership mechanism and the
  information dissemination protocols.
\item causality: includes the causality tracking structure that guarantees a
  delivery order of operations reflecting a form of causality.
\item sequence structure: includes the structure that guarantees a global
  total order among elements of the sequence.
\item graphical user interface: includes the editor as a graphical entity that
  users can interact with inside web browsers.
\end{inparaenum}
The left part of the figure depicts the common process chain: when the user
performs an operation on the document, the operation is applied to the shared
sequence which creates an \LSEQ identifier. Then it decorates the result of the
operation with causality tracking metadata. Finally, \CRATE broadcasts it using
the neighborhood provided by the \SPRAY random peer sampling protocol.
Conversely, when \CRATE receives a broadcast message, it checks if the operation
is causally ready to be delivered. Once the condition is verified, it applies
the operation to the shared sequence which notifies the graphical user interface
of the changes.  The right part of the figure corresponds to the catch up
strategy where a peer may have missed operations due to dropped messages, or
simply because the peer worked on offline mode for a while. Therefore, it
regularly asks to its neighborhood the missing operations using the differences
of version vectors.

The rest of this section reviews each layer and details the component inside
them.

\begin{figure}
  \centering
  \input{./input/architecture.tex}
  \caption{\label{fig:architecture}The four layers of \CRATE's architecture}
\end{figure}

\subsection{Communication}
\label{subsec:communication}

To collaboratively edit a document, users must establish a form of communication
between them. It firstly requires to build a network of communication
channels. It secondly requires to use it to disseminate the changes performed on
the shared document to all participants.  \CRATE uses
\SPRAY~\cite{nedelec2015spray} as membership protocol and relies on its
properties to efficiently disseminate the messages.

\begin{asparadesc}
\item [The membership protocol,] called \SPRAY, is a random peer sampling
  protocol~\cite{jelasity2007gossip} the primary target of which is WebRTC, a
  recent technology that allows peer-to-peer communication between web browsers.
  As such, the range of users includes small devices (e.g. smartphones, tablets,
  etc.) and establishing a connection requires a three-way handshake. These
  constraints invite to maintain a small number of connections.

  Using \SPRAY, each member owns a set of neighbors which dynamically grows and
  shrinks to reflect the network size. Without any global knowledge,
  \begin{inparaenum}[(i)]
  \item it provides each member with a neighborhood of logarithmic size compared
    to the global network size;
  \item it quickly converges to a topology exposing similarities with random
    graphs~\cite{erdos1959random}. Among others,
    \begin{inparaenum}[(a)]
    \item it balances the load among members by repeatedly averaging over time the
      size of neighborhoods pairwise;
    \item it becomes robust to random crashes or unexpected departures of
      members;
    \item the shortest average distance to reach all peers stays small.
    \end{inparaenum}
  \end{inparaenum}
  
  \SPRAY divides the life-cycle of a member into three phases: the joining, the
  exchanges, and the leaving. They respectively aim to increase, retain, and
  decrease the number of connections to follow a logarithmic progression.

\item [The information dissemination protocol]\cite{birman1999bimodal} aims to
  propagate the changes performed by the user on their shared document. Any
  operation must reach all members (broadcast) to guarantee eventual
  consistency. The dissemination relies on the neighborhood provided by
  \SPRAY. When a user performs an operation, \CRATE prepares a message including
  the result of the operation and sends it to the whole network using its
  neighborhood. Neighbors receiving such message forward it to their own
  neighbors. Hence, messages reach all participants transitively. To guarantee
  termination and limit the flooding, each member forwards each message to their
  neigbhors only once by using a version vector with exceptions
  (cf. Section~\ref{subsec:causality}).

  The information dissemination protocol impacts the communication complexity at
  each peer:
  \begin{equation}
    \mathcal{O}(m.\ln |\mathcal{R}| )
  \end{equation}
  where $m$ is the message size determined by the layers below, and
  $|\mathcal{R}|$ is the number of replicas in the network including both
  writers and readers of the shared sequence.
\end{asparadesc}

\subsection{Causality tracking}
\label{subsec:causality}

To guarantee the exactly once delivery of operations, and the causal delivery of
semantically related operations, \CRATE uses a version vector with
exceptions~\cite{malkhi2007concise, mukund2014optimized}.

\begin{asparadesc}
\item [Version vector with exceptions] store for each member
  \begin{inparaenum}[(i)]
  \item an integer denoting the maximum counter of operations originated from
    this site and
  \item a list of integers denoting the exceptions, i.e., the operations known
    as not received yet.
  \end{inparaenum}
  
  A unique member identifier along with a monotonically growing counter allows
  differentiating each operation. Thus, when a member performs a change to its
  shared document, it increments its local counter. Then it decorates the
  message with its counter and identifier. Upon reception, \CRATE checks in the
  version vector with exceptions if it already received the operation
  earlier. In this case, it simply discards the operation.  Otherwise, it checks
  if the operation depends on another one. In this case, \CRATE delivers the
  operation if this other operation is delivered. Otherwise, it puts the
  operation in a buffer awaiting for the dependency to arrive. Upon delivery, it
  integrates the operation identifier to the version vector with exceptions.

  \begin{figure}
    \input{./input/timelineexample.tex}
    \caption{\label{fig:timeline} Causality tracking example.}
  \end{figure}

  Figure~\ref{fig:timeline} depicts an editing session involving 3 users. The
  version vector with exceptions starts empty. Member $m_1$ inserts two
  characters in its document and broadcasts the corresponding messages. Member
  $m_3$ quickly receives both operations. Since it did not receive these
  operations before, and since they do not depend of any other operation, it
  integrates the operation identifiers to its causality structure. It also
  delivers the operation to the shared sequence structure
  (cf. Section~\ref{subsec:sequence}). In the meantime, Member $m_2$ only
  receives the second operation. Consequently, it marks the first operation of
  $m_1$ as exception and still integrates the received operation. Then, $m_3$
  removes the first character inserted by $m_1$ and broadcasts it. While $m_1$
  delivers the removal immediately, $m_2$ waits since the targeted operation
  belongs to the exceptions. Once it receives the missing first operation of
  $m_1$, the exception disappears and the delete operation is performed.

  The local upper-bound on space complexity is:
  \begin{equation}
    \mathcal{O}(|\mathcal{W}|)
  \end{equation}
  where $|\mathcal{W}|$ is the number of writers, i.e., users who modified the
  document at least once.  Such structure only requires to piggyback the
  identifiers of operation. Hence, the upper-bound on communication complexity
  is:
  \begin{equation}
    \mathcal{O}(o.\ln |\mathcal{R}|)
  \end{equation}
  where $o$ is the operation size determined by the shared sequence structure
  (cf. Section~\ref{subsec:sequence}), and the rest is determined by the
  communication layer (cf. Section~\ref{subsec:communication}).
  
\item [The anti-entropy protocol] periodically checks if the local replica
  diverges from another neighbor's one at random. It aims to retrieve missing
  operations that could have been lost during transmissions. For this purpose, a
  simple difference between vectors suffices.

  For instance, in the prior example depicted by Figure~\ref{fig:timeline},
  Member $m_2$ receives the second operation of $m_1$ before its first. To catch
  up, $m_2$ could send its version vector with exceptions to one of its
  neighbors chosen at random. Assuming that it picks $m_3$, the latter detects
  that, compared to its own vector, the remote member missed the first operation
  of $m_1$. Then, it sends it back to $m_2$ along with its own vector. Finally,
  $m_2$ follows the normal process for the received operations, and additionnaly
  merges its vector with the received one.

  Such protocol does not require any additional local metadata. However, the
  communication cost is prohibitively high which encourages to perform this
  reconciliation protocol with great care:
  \begin{equation}
    \mathcal{O}(|\mathcal{W}|+|\mathcal{W}|+x.o)
  \end{equation}
  where the first $|\mathcal{W}|$ designates the vector contained in the
  initiating message, and $|\mathcal{W}|+x.o$ the response to this message where
  $x.o$ are the missing operations.
\end{asparadesc}

\subsection{Shared sequence}
\label{subsec:sequence}

To guarantee eventually consistent\cite{bailis2013eventual} replicas of the
shared document, \CRATE uses a conflict-free replicated data type for
sequences~\cite{shapiro2011comprehensive, shapiro2011conflict} with the
allocation function \LSEQ~\cite{nedelec2013concurrency, nedelec2013lseq} for its
unique and immutable identifiers.

\CRATE uses \LSEQ, a polyLogarithmic identifier allocator for SEQuences. Its
underlying structure is an exponential tree which, when linearized using its
global total order, results in the sequence of elements representing the
document. \LSEQ comprises two parts:
\begin{inparaenum}[(i)]
\item the function $allocPath$ which chooses the path in the tree for the
  newly allocated identifier.
\item the function $allocDis$ which decorates the path in order to ensure its
  uniqueness even in presence of concurrent insertions.
\end{inparaenum}

The function $allocPath$ chooses the path associated with each element in order
to encode its relative position with regard to its adjacent elements in the
sequence. For the sake of performance, the aim of $allocPath$ is to keep the
underlying tree with a small depth. Three components compose $allocPath$. Each
of these components fails to provide an efficient allocation
function. Nevertheless, their composition allows to get the best of each by
canceling their respective deficiency.
\begin{asparadesc}
\item [An exponential tree]~\cite{andersson1996faster,andersson2007dynamic}
  represents the shared document. The path is a sequence of numbers chosen among
  a subset of numbers the size of which is doubled at each concatenation. For
  instance, if a path $p_1$ of size 1 is chosen among [$\mathbb{N}_{<32}$], a
  path $p_2$ of size 2 is chosen among [$\mathbb{N}_{<32}.\mathbb{N}_{<64}$]
  etc. Let $r$ be the number of possible paths with one concatenation (i.e., the
  maximum arity of the root of the tree), a path $p_k$ of size $k$ is chosen
  among [$\mathbb{N}_{<r}.\mathbb{N}_{<2r}\ldots\mathbb{N}_{<2^{k-1}r}$].  Due
  to the growth of the subsets, such representation of the paths requires one
  additional bit to encode each concatenation. With the same examples, it
  implies that $p_1$ is encoded using $log_2(32)=5$ bits, $p_2$ is encoded using
  $5+6=11$ bits,~\ldots Thus, a path is encoded by:
  \begin{equation}
    \sum\limits_{i=1}^{k}(\log_2(r)+i) =
    k\log_2(r) + {k(k+1)\over{2}} = \mathcal{O}(k^2) \,\, bits
  \end{equation}
  When an exponential tree of depth $k$ is balanced (i.e., all its branches
  are filled) it holds uptil:
  \begin{equation} \sum\limits_{i=0}^{k-1} {2^{(i^2-i)/2}} \,\, elements
  \end{equation}
  When an exponential tree of depth $k$ has one branch filled per level, it
  holds uptil:
  \begin{equation} 2^{k+1}-1 \,\, elements\end{equation} 
  In the worst case, the tree contains one element per level.
  
  An alphabetical order maintains a dense total order among elements in the
  tree. It primary uses the path of elements alongside globally unique markers
  called disambiguators. The latter's objective is twofold:
  \begin{inparaenum}[(i)]
  \item to order concurrent operations that happen to have an identical path and
  \item to allow the allocation of new identifiers in-between them.
  \end{inparaenum}
  For instance, let [3] be the path of Element Q inserted by User $u_x$, and let
  [4] the path of Element T inserted by User $u_y$. When a user $u_1$ inserts W
  between those elements, the depth of the tree must grow to welcome the new
  element. Assuming that depth 1 has a maximum arity of 8, the identifier is
  allocated in the range from [3.0] to [3.15].  In this example, the resulting
  path is [3.6]. In the meantime, another user $u_2$ inserts R between Q and T
  which happens to result in the path [3.6] too. To ensure a total order,
  disambiguators are associated with each path composed of a monotonically
  growing counter and a globally unique site identifier. Here, the identifier of
  Element W is composed of the path [3.6] and disambiguator
  [$\langle u_x,\,1\rangle$, $\langle u_1,\,1$] and the Element R is composed of
  the path [3.6] and disambiguator [$\langle u_x,\,1\rangle$,
  $\langle u_2,\,1\rangle$].  The comparison starts to examine the first
  concatenations which are equal.  Then, the comparison concerns the path of the
  second level of the tree which are equals too. Hence, it examines the
  disambiguators to determine that W is located before R because $u_x < u_y$ in
  this case. The resulting sequence is QWRT.
  
\item [Two sub-allocation functions] designed for monotonic editing, i.e.,
  inserting repeatedly at an adjacent position of the previously inserted
  element. These are application dependent. While one is well-suited to
  end-editing (left-to-right), the other is well-suited for front-editing
  (right-to-left). To achieve this, they respectively allocate paths close of
  the leftmost path, and rightmost path in order to preserve space for the
  future insertions. Hence, the left-to-right allocation function leaves
  available paths at the right of the tree, while the right-to-left function
  aims the opposite. For instance, a user writes QWERTY starting from the Q to
  the Y. Using the left-to-right allocation function leads to identifiers like
  [2], [4], [7], [7.2], [7.5], [7.9]. Small space is left in-between paths to
  handle mistakes, e.g., a user misses some characters while typing.  Since
  accurately predicting the editing behavior of users is \TODO{impossible},
  \LSEQ uses these two antagonist strategies to adapt to any editing behaviors
  assuming that edition is mostly about compositions of sequences of monotonic
  insertions.
  
\item [A hash function] chooses among the two sub-allocation functions. The
  choice is made randomly using a hash function following a uniform
  distribution. Such function does not favor any editing behavior while
  remaining efficient. This provides the independence of the allocation function
  from any editing strategy. Furthermore, as shown
  in~\cite{nedelec2013concurrency}, using antagonist sub-allocation functions
  forces all peers to make identical choices. To reach that goal, they all use a
  similar hash function initialized with a common seed and shared within the
  document. When a user inserts a new element in the sequence, \LSEQ firstly
  processes the depth of the new path, and secondly defers the allocation to the
  function designated by the hash of the depth.
\end{asparadesc}

% \begin{algorithm}[h]
%   \input{input/allocpathalgo.tex}
%   \caption{The $allocPath$ function of \LSEQ}
%   \label{algo:allocpathalgo}
% \end{algorithm}
  

% \begin{algorithm}
%   \input{input/allocdesalgo.tex}
%   \caption{\label{algo:allocdis}The function $allocDis$ of \LSEQ}
% \end{algorithm}

% In text editing, most of the editing behaviors can be empirically summarized
% as a composition of two basic editing behaviors.
% \begin{inparaenum}[(i)]
% \item The random editing behavior where the author inserts new elements at
%   what appears random positions in the sequence. For instance, this behavior
%   mostly arises when syntactic corrections are performed, e.g., the author
%   writes $QWETY$ and realizes that the $R$ is missing. She adds the missing
%   character in a second time.
% \item The monotonic editing behavior where the author repeatedly inserts new
%   elements between the last inserted element and an adjacent element (after or
%   before exclusively). For instance, when an author writes $QWERTY$, she
%   generally starts from the first letter $Q$ to the last letter of the word
%   $Y$. On the opposite, insertions in a logfile are usually performed at the
%   beginning for practical reasons.
% \end{inparaenum}

% As a consequence, we focus on the space complexity analysis of \LSEQ to
% random and monotonic editing behaviors to which we add a worst-case complexity
% analysis.  The analysis does not include an average case since it requires to
% know the average distribution of the position of edits performed by a human
% collaborator which is obviously very complex.

\begin{table*}
  \centering
  \input{input/lseqcomplexitiestable.tex}
  \caption{\label{table:lseqcomplexities}
    Upper-bound on space and time complexities of \LSEQ. Where $I$ is the number
    of insert operations performed.}
\end{table*}

\TODO{To summarizes, the space complexity analysis reveals that the allocation
function \LSEQ sacrifices on the worst-case space complexity to improve the
space complexity of the monotonic editing behaviors. Nevertheless, in text
editing, the worst-case happens with a very low probability compared the other
cases. Furthermore, it is worth noting that usually, the authors do not write a
document in a single round, starting from the beginning to go straight up to
the end (as the monotonic analysis could suggest). On the contrary, the authors
write sections, structure the documents, perform corrections, rewrite parts of
the document, reorganize, etc. This behavior (between random and monotonic
behavior) tends to even up the branches of the underlying tree of \LSEQ. In
the case of random editing, the space complexity is asymptotically optimal
$O(log\,n)$ while it is very interesting in a "normal setting" $O((log\,n)^2)$.}

\begin{figure*}
  \centering
  \subfloat {\input{input/lseqtreeexampleA.tex}}
  \hspace{10pt}
  \subfloat {\input{input/lseqtreeexampleB.tex}}
  \caption{\label{fig:lseqtreeexample}\LSEQ tree handling two monotonic
    editing behaviors.}
\end{figure*}


Figure~\ref{fig:lseqtreeexample} depicts the resulting trees after two
antagonist scenarios creating the sequence $QWERTY$
\begin{inparaenum}[(i)] 
\item the left-to-right editing sequence [($Q,\,0$), ($W,\,1$), \ldots] and
\item the right-to-left editing sequence [($Y,\,0$), ($T,\,0$), \ldots].
\end{inparaenum}
In both cases, the exponential tree of \LSEQ starts with an arity $32$ and
doubles it at each level. Also, it uses the $frontEditing$ and $endEditing$
sub-allocation functions at the first and the second level of the tree
respectively. Since the first level of the tree uses the function $endEditing$,
the scenario involving the left-to-right editing sequence results in a tree of
depth 1. On the other hand, contrarily to the allocation function presented in
Figure\ref{fig:allocpathexample}), the antagonist scenario does not increase
very much the depth of the tree. Indeed, the identifiers of \LSEQ quickly reach
a level of the tree where the sub-allocation function is designed to handle the
right-to-left editing behavior.


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../paper"
%%% End: 

% LocalWords:  disambiguator neighbours
