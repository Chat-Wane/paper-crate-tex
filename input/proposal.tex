
\section{CRATE}
\label{sec:proposal}

\CRATE (stands for CollaboRATive Editor) is a distributed and decentralized
collaborative editor running as a web application. As depicted in
Figure~\ref{fig:architecture}, \CRATE's architecture comprises four layers:
\begin{inparaenum}[(i)]
\item communication: includes the editing session membership mechanism and the
  information dissemination protocols.
\item causality: includes the causality tracking structure that guarantees a
  delivery order of operations reflecting a form of causality.
\item sequence structure: includes the structure that guarantees a global
  total order among elements of the sequence.
\item graphical user interface: includes the editor as a graphical entity that
  users can interact with inside web browsers.
\end{inparaenum}
The left part of the figure depicts the common process chain: when the user
performs an operation on the document, the operation is applied to the shared
sequence which creates an \LSEQ identifier. Then it decorates the result of the
operation with causality tracking metadata. Finally, \CRATE broadcasts it using
the neighborhood provided by the \SPRAY random peer sampling protocol.
Conversely, when \CRATE receives a broadcast message, it checks if the operation
is causally ready to be delivered. Once the condition is verified, it applies
the operation to the shared sequence which notifies the graphical user interface
of the changes.  The right part of the figure corresponds to the catch up
strategy where a peer may have missed operations due to dropped messages, or
simply because the peer worked on offline mode for a while. Therefore, it
regularly asks to its neighborhood the missing operations using the differences
of version vectors.

\begin{figure}
  \centering
  \input{./input/architecture.tex}
  \caption{\label{fig:architecture}\CRATE architecture}
\end{figure}

\begin{asparadesc}

\begin{figure}
  \centering
  \input{input/networkexample.tex}
  \caption{\label{fig:network}Small network example. Each square represents a
    web browser. Each arrow represents a WebRTC connections established from
    browser-to-browser. \TODO{show information dissemination.}}
\end{figure}

\item [The communication layers] includes both an information dissemination
  protocol and a random peer sampling protocol. While the former is very simple
  since it is only in charge of sending and receiving the operations, the latter
  is complex.

  \SPRAY is an adaptive random peer sampling protocol whose primary target is
  WebRTC, a recent technology that allows peer-to-peer communication between web
  browsers. WebRTC has additional constraints such as the range of users which
  includes small devices (e.g. smartphones, tablets, etc.), and its complex
  3-way connection establishment. Indeed, as depicted in \TODO{Figure}, a user
  $u_1$ wishing to establish a connection with a user $u_2$ must create an offer
  ticket and send it to $u_2$ through a mediator (e.g. by mail, dedicated
  servers, peers already connected in the network). Then, $u_2$ must answer with
  another offer (referred to as \emph{stamped ticket}) using a mediator
  too. Finally, $u_1$ must confirm the connection to establish the bidirectional
  link. Due to this complex protocol, the peer sampling protocols are encouraged
  to keep a small number of connections.

  \SPRAY is adaptive in the sense that the neighborhood maintained at each peer
  grows and shrinks logarithmically compared to the number of members in the
  editing session. \SPRAY divides the life-cycle of a peer into three phases:
  the joining, the exchanges, and the leaving. They respectively aims to
  increase, keep unchanged, and decrease the number of connections to follow a
  logarithmic progression.
  
  When a user perform an operation on the shared sequence, \CRATE prepares a
  message including the result of the operation and broadcasts it to the whole
  network using its neighborhood. In a second time, the neighbors receiving such
  message forward it to their own neighbors. Hence, the message reaches all
  participants transitively. The stopping condition checks if the message has
  already been received previously using the version vector with
  exceptions. Therefore, each message is forwarded only once. Thus, this layer
  impacts the communication complexity of each peer as:
  \begin{equation}
    \mathcal{O}(m.\ln |\mathcal{R}| )
  \end{equation}
  where $m$ is the message size determined by the layers below, and
  $|\mathcal{R}|$ is the number of replicas in the network. The latter includes
  both writers and readers of the shared sequence.
  
  \SPRAY also has properties similar of those of random
  graphs~\cite{erdos1959random}. In particular,
  \begin{inparaenum}[(i)]
  \item the shortest average distance to reach all peers stays low, even with a
    large number of participants. Thus, messages disseminates quickly to
    everyone.
  \item The load of peers is balanced, i.e., no peer is more important than
    another in terms of connections. Therefore, the network is robust to random
    crashes of peers.
  \end{inparaenum}

\item [The causality tracking layer] guarantees that operations are not
  delivered more than once, and that operations depending on another operation
  is delivered after the latter. \CRATE uses a version vector with
  exceptions~\cite{malkhi2007concise} which stores for each
  site
  \begin{inparaenum}[(i)]
  \item an integer denoting the maximum counter of operations originated from
    this site and
  \item a list of integers denoting the exceptions, i.e., the counter of
    operations known as not received yet.
  \end{inparaenum}

  Each operations is uniquely identified by its unique site identifier and a
  monotonically growing counter. On operation reception, \CRATE discards the
  operation if it has already been received before. Otherwise, it modifies the
  version vector entry either by updating the maximum counter or removing an
  entry in the exceptions.

  \begin{figure}
    \input{./input/timelineexample.tex}
    \caption{\label{fig:timeline}Causality tracking example.}
  \end{figure}

  Figure~\ref{fig:timeline} depicts a scenario where 3 peers are involved. Thus,
  all peers have a vector of three entries. Peer $p_1$ inserts two elements in
  the sequence and broadcasts the operations. Peer $p_3$ immediately receives
  both operations and increments the entry in its version vector accordingly.
  In the meantime, Peer $p_2$ only receives the second operation which leads to
  an update of the maximum counter and an exception concerning the first
  operation of Peer $p_1$. Then, Peer $p_3$ removes the first element inserted
  by $p_1$ and broadcast it. While $p_1$ delivers the removal immediately, Peer
  $p_2$ has to wait since the targeted operation belongs to the exceptions. Once
  it receives the first operation of $p_1$, the exception disappears and the
  delete operation is performed.

  The local space complexity of such data structure depends of the number of
  writers $|\mathcal{W}|$, i.e., the users that modified the document at least
  once:
  \begin{equation}
    \mathcal{O}(|\mathcal{W}|)
  \end{equation}
  The communication complexity is not impacted from this data structure. Therefore, 
  its becomes:
  \begin{equation}
    \mathcal{O}(o.\ln |\mathcal{R}|)
  \end{equation}
  where $o$ is the operation size determined by the shared sequence structure,
  and the rest is determined by the communication layer.

  The anti-entropy periodically checks if the local replica diverges from
  another neighbor's one at random. It aims to retrieve missing operations that
  could have been lost during the transmissions. \TODO{example}. There is no
  additional cost on local memory. However, the communication cost is
  prohibitively high which encourages to perform this reconciliation protocol
  with great care:
  \begin{equation}
    \mathcal{O}(|\mathcal{W}|+|\mathcal{W}|+x.o)
  \end{equation}
  where the first $|\mathcal{W}|$ designates the initiating message, and
  $|\mathcal{W}|+x.o$ the response to this message where $x.o$ are the missing
  operations.

\end{asparadesc}

\begin{asparadesc}
\item [The shared sequence layer] uses a conflict-free replicated data type for
  sequences~\cite{shapiro2011comprehensive, shapiro2011conflict}. It is an
  abstract data type for sequences that provides two commutative operations:
  insert and delete. As such, the delivery order of operations does not matter
  as long as the deletion of an element follows its insertion. This property
  makes these shared sequences tolerant to concurrency. However, their
  complexity lies in their space consumption. Indeed, each insert operation
  allocates a unique and immutable identifier to the element. A global total
  order among the identifiers guarantees that replicas eventually converge to an
  identical states.

  \CRATE uses \LSEQ, a polyLogarithmic identifier allocator for SEQuences. Its
  underlying structure is an exponential tree which, when linearized using its
  global total order, results in the sequence of elements representing the
  document. \LSEQ comprises two parts:
  \begin{inparaenum}[(i)]
  \item the function $allocPath$ which chooses the path in the tree for the
    newly allocated identifier.
  \item the function $allocDis$ which decorates the path in order to ensure its
    uniqueness even in presence of concurrent insertions.
  \end{inparaenum}

  The function $allocPath$ chooses the path associated with each element in
  order to encode its relative position with regard to its adjacent elements in
  the sequence. For the sake of performance, the aim of $allocPath$ is to keep
  the underlying tree with a small depth. Three components compose
  $allocPath$. Each of these components fails to provide an efficient allocation
  function. Nevertheless, their composition allows to get the best of each by
  canceling their respective deficiency.
  \begin{enumerate}[leftmargin=*]
  \item The first component is an exponential
    tree~\cite{andersson1996faster,andersson2007dynamic}. The path is a sequence
    of numbers chosen among a subset of numbers whose size is doubled at each
    concatenation. For instance, if a path $p_1$ of size 1 is chosen among
    [$\mathbb{N}_{<32}$], a path $p_2$ of size 2 is chosen among
    [$\mathbb{N}_{<32}.\mathbb{N}_{<64}$] etc. Let $r$ be the number of possible
    paths with one concatenation (i.e., the maximum arity of the root of the
    tree), a path $p_k$ of size $k$ is chosen among
    [$\mathbb{N}_{<r}.\mathbb{N}_{<2r}\ldots\mathbb{N}_{<2^{k-1}r}$].  Due to
    the growth of the subsets, such representation of the paths requires one
    additional bit to encode each concatenation. With the same examples, it
    implies that $p_1$ is encoded using $log_2(32)=5$ bits, $p_2$ is encoded
    using $5+6=11$ bits,~\ldots Thus, a path is encoded by:
    \begin{equation}
      \sum\limits_{i=0}^{k-1}(\log_2(r)+i) =
      k\log_2(r) + k(k+1)/2 = \mathcal{O}(k^2) \,\, bits
    \end{equation}
    When an exponential tree of depth $k$ is balanced (i.e., all its branches
    are filled) it holds uptil:
    \begin{equation} \sum\limits_{i=0}^{k-1} {2^{(i^2-i)/2}} \,\, elements
    \end{equation}
    When an exponential tree of depth $k$ \TODO{has one branch filled of elements per
    element}, it holds uptil:
    \begin{equation} 2^{k+1}-1  \,\, elements\end{equation}


    The total order $<_{\mathcal{P}}$ is similar to the lexicographic order. We
    define it as $\forall p_j,\,p_k\in\mathcal{P}$ with $|p_j|=j$,
    $|p_k|=k$. There exists an index $0\leq l\leq min(|p_j|,|p_k|)$ such that
    $p_j = X.Y$ and $p_k = X.Z$ with $X\subset \{\mathbb{N}\}^l$,
    $Y \subset \{\mathbb{N}\}^{j-l}$, $Z \subset \{\mathbb{N}\}^{k-l}$. Finally,
    $p_j<_{\mathcal{P}}p_k$ iff $Y[1]<Z[1]$.
  \item The function $allocPath$ uses two sub-allocation functions both designed
    for monotonic editing, i.e., inserting repeatedly at an adjacent position of
    the previously inserted element. These are application dependent; one is
    well-suited to end-editing (left-to-right) while the other is well-suited
    for front-editing (right-to-left).
  \item The function $allocPath$ uses a third component to choose the
    sub-allocation function employed at each depth of the exponential tree. The
    choice is made randomly using a hash function following a uniform
    distribution. Such function does not favor any editing behavior while
    remaining efficient. This provides the independence of the allocation
    function from any editing strategy/policy. Furthermore, as shown
    in~\cite{nedelec2013concurrency}, using antagonist sub-allocation functions
    forces all peers to make identical choices. To reach that goal, they all use
    a similar hash function initialized with a same seed and shared within the
    document.
  \end{enumerate}

  Combining the three components provides identifiers with a sub-linear average
  size compared to the number of insertions performed which makes it well-suited
  for text editing, and consequently, for distributed collaborative editing.
\end{asparadesc}

\begin{algorithm}[h]
\input{input/allocpathalgo.tex}
\caption{The $allocPath$ function of \LSEQ}
\label{algo:allocpathalgo}
\end{algorithm}

\begin{asparadesc}
\item[Example:] Similarly to the example of Figure~\ref{fig:allocpathexample})
   the example given in Figure~\ref{fig:lseqtreeexample} depicts the resulting
   trees after two antagonist scenarios creating the sequence
   $QWERTY$ \begin{inparaenum}[(i)] \item the left-to-right editing sequence
     [($Q,\,0$), ($W,\,1$), \ldots] and \item the right-to-left editing sequence
     [($Y,\,0$), ($T,\,0$), \ldots]. \end{inparaenum} In both cases, the
   exponential tree of \LSEQ starts with an arity $32$ and doubles it at each
   level. Also, it uses the $frontEditing$ and $endEditing$ sub-allocation
   functions at the first and the second level of the tree respectively. Since
   the first level of the tree uses the function $endEditing$, the scenario
   involving the left-to-right editing sequence results in a tree of depth 1. On
   the other hand, contrarily to the allocation function presented in
   Figure\ref{fig:allocpathexample}), the antagonist scenario does not increase
   very much the depth of the tree. Indeed, the identifiers of \LSEQ quickly
   reach a level of the tree where the sub-allocation function is designed to
   handle the right-to-left editing behavior.
\end{asparadesc}

% \begin{asparadesc}
% \item [The function allocDis] creates the di\-sam\-bi\-gua\-tors which have two
%   goals.  It ensures the uniqueness of the triples, even in presence of
%   concurrency and it guarantees that triples can always be inserted between two
%   other triples even when the paths of the latter are identical. The example of
%   Figure~\ref{fig:allocpathexample} illustrates the need of comparisons that
%   preserve the order given by the paths and also examines the
%   disambiguators. During the editing session, the insertion between the
%   elements $W$ and $T$ resulted in an identical path [$29$]. Therefore, without
%   $allocDis$, the order among $W$ and $T$ is ambiguous, and inserting between
%   them becomes impossible. Indeed, if any path [$29.X$] is greater than [$29$],
%   the newly inserted elements will always end up after the $W$ and $T$ in the
%   sequence. Consequently, the disambiguators are necessary to build an
%   allocation function for sequences.
% \end{asparadesc}

% A disambiguator is a list of pairs $\langle source,\, clock\rangle$. Similarly
% to the tree of paths, the set of all disambiguators can be represented as a
% tree equipped with a lexicographic total order
% $(\mathcal{D},\, <_{\mathcal{D}})$. While the total order $<_{\mathcal{P}}$
% ultimately compares two numbers, the total order $<_{\mathcal{D}}$ compares two
% pairs. With the same notation than $allocPath$, let $\langle s_1,\, c_1\rangle$
% and $\langle s_2,\,c_2\rangle$ be the $l+1$ couples of the disambiguators $d_j$
% and $d_k$ respectively. $d_j <_{\mathcal{D}}d_k$ iff $s_1 < s_2$, or if
% $s_1=s_2$, $c_1 < c_2$.

% \begin{algorithm}
%   \input{input/allocdesalgo.tex}
%   \caption{\label{algo:allocdis}The function $allocDis$ of \LSEQ}
% \end{algorithm}

% Algorithm~\ref{algo:allocdis} describes the allocation of a disambiguator which
% preserves the intention of the peer that performed the insertion. Identically
% to Lamport timestamps, it uses a unique site identifier and a monotonically
% increasing counter. Basically, it copies the disambiguator of its neighbours at
% the depth where they are equal, and, if none is equal, it copies its own site
% and counter. The latter case happens at least once per insertion which
% guarantees the uniqueness of each identifier. The space complexity of
% disambiguator is upper-bounded by the length of the new path. Furthermore,
% depending on the scenario, it can be drastically compressed.

% Let us go back to the example in Figure~\ref{fig:treemodelexample}. In this
% tree, collaborator $p_1$ inserts the character $R$ between the two pairs
% $\langle [3],\, E\rangle$ and $\langle [4],\, T\rangle$. The resulting path is
% $[3.1]$. Now, we add the disambiguators $\delta_E = [\langle 2,\,1\rangle]$
% meaning that it is the first insertion of collaborator $p_2$, and
% $\delta_T = [\langle 3,\,1\rangle]$ meaning that it is the first insertion of
% collaborator $p_3$. The resulting path associated with $R$ is $[3.1]$. Since
% the first integer of the path of $R$ is similar to the path of the character
% $E$, the algorithm copies the first part of $\delta_E$. Then, since none of the
% adjacent pairs have a length of $2$, the algorithm copies the values of $p_1$,
% i.e. $\langle 1,\,1\rangle$. The resulting disambiguator is
% $[\langle 2,\,1\rangle,\, \langle 1,\,1\rangle]$. This way, $p_1$ inserts a new
% character between $E$ and $R$. As we get the path $[3.0.X]$, the resulting
% disambiguator is
% $[\langle 2,\,1\rangle,\,\langle 1,\,2\rangle,\,\langle 1,\,2\rangle]$.

% \begin{asparadesc}
% \item [The global total order] $(\mathcal{I}, <_{\mathcal{I}})$ is a
%   composition of the aforementioned sets $\mathcal{P}$ and $\mathcal{D}$, and
%   their respective total orders $(\mathcal{P},\, <_{\mathcal{P}})$ and
%   $(\mathcal{D},\, <_{\mathcal{D}})$.
% \end{asparadesc}

% The global total order is defined as:
% $\forall p,\,q \in \mathcal{I}, p<q \Leftrightarrow \exists i$ with
% $\forall_{k=0}^{i-1}, \, p.P(k) = q.P(k) \wedge p.D(k) = q.D(k)$ such that
% $\exists j=i+1$ with
% $p.P(j) < q.P(j) \vee (p.P(j) = q.P(j) \wedge p.D(j) < q.D(j))$.

% \subsection{Space complexity}
% \label{sec:spacecomplexity}

In text editing, most of the editing behaviors can be empirically summarized
as a composition of two basic editing behaviors.
\begin{inparaenum}[(i)]
\item The random editing behavior where the author inserts new elements at
  what appears random positions in the sequence. For instance, this behavior
  mostly arises when syntactic corrections are performed, e.g., the author
  writes $QWETY$ and realizes that the $R$ is missing. She adds the missing
  character in a second time.
\item The monotonic editing behavior where the author repeatedly inserts new
  elements between the last inserted element and an adjacent element (after or
  before exclusively). For instance, when an author writes $QWERTY$, she
  generally starts from the first letter $Q$ to the last letter of the word
  $Y$. On the opposite, insertions in a logfile are usually performed at the
  beginning for practical reasons.
\end{inparaenum}

As a consequence, we focus on the space complexity analysis of \LSEQ to
random and monotonic editing behaviors to which we add a worst-case complexity
analysis.  The analysis does not include an average case since it requires to
know the average distribution of the position of edits performed by a human
collaborator which is obviously very complex.

Also, since the space complexity of disambiguators provided by $allocDis$ is
upper bounded by the paths allocated by $allocPath$, the space complexity
analysis of the path is reduced to the space complexity of the identifiers of
\LSEQ.

\begin{asparadesc}
\item [Random editing behavior] is equivalent to a uniform distribution of the
  positions of the insert operations within the range of the sequence. As a
  consequence, the underlying tree of the allocation function is
  balanced. Depending on the depth $k$, the tree can hold a number $n$ of
  elements: \begin{equation} n = \sum\limits_{i=0}^{k}
    {2^{(i^2-i)/2}} \end{equation} Therefore, after $n$ insert operations
  performed on the sequence, the number of concatenations composing a path is
  upper-bounded by:
  \begin{equation} O(\sqrt{log\,n}) \end{equation} Furthermore, a path is a
  sequence of numbers $[a_1.a_2\ldots$ $a_k]$. Each number $a_j$ requires one
  more bit than its preceding number $a_{j-1}$. Let $b$ be the number of bits
  to encode $a_0$. Thus, a path is encoded by:
  \begin{equation} \sum\limits_{i=1}^{k}b+i = kb + k(k+1)/2 = O(k^2) \,
    bits \end{equation} By a simple replacement of $k$ in the latter expression
  by the former, the resulting space complexity of identifiers is the optimal
  bound:
  \begin{equation} O(log\,n) \, bits \end{equation}
  
\item[Monotonic editing behavior] is similar to repeatedly:
  \begin{inparaenum}[(i)]
  \item fill one branch of the tree and
  \item increase the depth of the tree.
  \end{inparaenum} Consequently, with a classical K-ary tree, the number of
  concatenations of the paths grows linearly. However, using an
  exponential tree, the number of available nodes in a branch still grows
  exponentially. Depending on the depth $k$, the tree can hold $n$ elements:
  \begin{equation} n = 2^{k+1}-1 \end{equation} Therefore, the number of
  concatenations of the path is:
  \begin{equation} O(log\,n) \end{equation} After the replacement of the
  variable $k$, we obtain the following space complexity of the monotonic
  editing behavior:
  \begin{equation} O((log\,n)^2) \, bits \end{equation}

\item [The worst-case] corresponds to one element per level in the
  tree. Therefore, the growth of the paths is linear for both K-ary tree and
  exponential tree. Thus, when $n$ insert operations are performed on the
  sequence, the number of concatenations composing a path is:
  \begin{equation} O(n) \end{equation} However, while the space complexity
  remains linear in the case of the N-ary tree, the exponential tree implies
  the following space complexity on its identifiers:
  \begin{equation} O(n^2) \, bits \end{equation}
\end{asparadesc}

\begin{table}
  \centering
  \begin{tabular}{@{}lccc@{}}
    \toprule
    & Random & Monotonic & Worst \\ \cmidrule{2-4}
    Id.size & $O(\sqrt{log\,n})$ & $O(log\,n)$ & $O(n)$ \\ \midrule
    Id.bit-length & \multicolumn{3}{c}{ $\sum\limits_{i=1}^{k}b+i =
      kb + k(k+1)/2 = O(k^2)$} \\ \midrule
    Space complexity & $O(log\,n)$ & $O((log\,n)^2)$ &
    $O(n^2)$ \\ \bottomrule
  \end{tabular}
  \caption{Spatial complexity of \LSEQ. Where $n$ is the number
    of insert operations performed. $k$ is the size of an identifier, i.e.,
    the number of concatenations. And $b$ the starting bit-length of numbers
    composing the identifiers.}
\end{table}

To summarizes, the space complexity analysis reveals that the allocation
function \LSEQ sacrifices on the worst-case space complexity to improve the
space complexity of the monotonic editing behaviors. Nevertheless, in text
editing, the worst-case happens with a very low probability compared the other
cases. Furthermore, it is worth noting that usually, the authors do not write a
document in a single round, starting from the beginning to go straight up to
the end (as the monotonic analysis could suggest). On the contrary, the authors
write sections, structure the documents, perform corrections, rewrite parts of
the document, reorganize, etc. This behavior (between random and monotonic
behavior) tends to even up the branches of the underlying tree of \LSEQ. In
the case of random editing, the space complexity is asymptotically optimal
$O(log\,n)$ while it is very interesting in a "normal setting" $O((log\,n)^2)$.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../paper"
%%% End: 

% LocalWords:  disambiguator neighbours
