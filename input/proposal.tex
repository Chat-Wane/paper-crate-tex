

\section{LSeq: a polylogarithmic path allocator}
\label{sec:proposal}

\LSEQ (polyLogarithmic SEQuence) is the name of the proposed allocation
function. Any sequence data structure using variable-size identifiers can use
it. Our prior works~\cite{nedelec2013concurrency, nedelec2013lseq} empirically
showed that \LSEQ provides a sublinear upper bound on its identifiers' space
complexity. Nevertheless, we did not provide any complexity analysis to support
these observations. In this section we prove the polylogarithmic growth of
\LSEQ's identifiers and state the conditions upon which it applies. The
complexity analysis also includes the space complexity of the replicated
structure, and the time complexity of operations provided by this structure.

\LSEQ improves the identifiers' space complexity by degrading its worst case
complexity. However, the worst case is made non-trivial. If a malicious user
tries to produce the worst case scenario, other editors can detect her easily,
for there is a large difference between the expected space complexity and the
worst case space complexity.

This section starts by describing the allocation strategy. Then, it provides its
complexity analysis.

\subsection{Allocation of paths}
\label{subsec:lseqallocation}

Function \textsc{allocPath} chooses the path associated with each element in
order to encode its relative position with regard to its adjacent elements in
the sequence. For the sake of performance, it aims to keep the underlying tree
with a small depth.

\begin{algorithm}
\input{input/allocpathalgo.tex}
\caption{\label{algo:allocpath}Allocation of paths}
\end{algorithm}

Algorithm~\ref{algo:allocpath} shows the instructions of \LSEQ. First,
\textsc{allocPath} processes the distance between the two paths in order to
retrieve the smallest level of the tree that contains enough room for the new
element.

Then, a \emph{hash function} $h$ defers the path allocation to a \emph{sub-allocation
function} depending on the depth found for the new path. The hash function of
every participant must give identical results~\cite{nedelec2013concurrency}.
% A hidden seed within the replicated document initializes it, for that all
% participants must make identical choices~\cite{nedelec2013concurrency}.
The choices between the sub-allocation functions must follow a uniform
distribution, for we have no knowledge about the future editing behaviors, and
we do not want to favor any.

\LSEQ uses two sub-allocation functions. Indeed, contrarily to state-of-the-art
approaches, \LSEQ uses an \emph{exponential
  tree}~\cite{andersson1996faster,andersson2007dynamic}. Such tree allows each
node to have twice as much children as its parents. Regarding the formalization
of Section~\ref{sec:preliminaries}, it means a restriction over
$\mathcal{P}$. The path is no longer a sequence of natural numbers but a
sequence of numbers chosen among a subset of $\mathbb{N}$, the size of which is
doubled at each concatenation. For instance, let us consider the path
[$\ell_1.\ell_2\ldots\ell_e$] with $\ell_1\in\mathbb{N}_{<2}$, then
$\ell_2\in \mathbb{N}_{<4}$, and $\ell_{e}\in\mathbb{N}_{<2^e}$. Compared to
constant arity trees, paths require an additional bit per concatenation, for the
subset are growing over depths. The binary size of a path is
$\textstyle\sum\nolimits_{i=1}^{e}\log_2{2^i}=\sum\nolimits_{i=1}^{e}i=
{e^2-e\over{2}}$.
Such growth forbids the existence of trivial editing behaviors leading to the
worst case allocation (e.g. Figure~\ref{fig:allocpathexample}).

Since one allocation function is not enough to characterize efficiently any
editing behavior, \LSEQ uses two functions with antagonist designs in order to
settle each other's weaknesses. Line~\ref{line:lefttoright} shows the
sub-allocation function that targets left-to-right editing behaviors such as the
one used in Figure~\ref{fig:allocpathexample}. Line~\ref{line:righttoleft} shows
the other one that targets the right-to-left editing behaviors. These
sub-allocation functions operate very similarly. The former chooses the
path starting from the preceding path and adds a small random value while the
latter chooses a path starting from the following path and subtracts a small
random value. They aim to leave more space for future insertions in queue and in
front of the new path, respectively.  When one of these sub-allocation functions
does not manage to provide small-sized paths, the other quickly takes the lead. In
such case, \LSEQ must be efficient enough to compensate the loss due to its
unsuitable choice of sub-allocation function.

\begin{figure}
  \centering
  \subfloat[Left-to-right case with \LSEQ.]
  [Left-to-right editing behavior.]
  {\input{input/lseqtreeexampleA.tex}}
  \subfloat[Right-to-left case with \LSEQ.]
  [Right-to-left editing behavior.]
  {\input{input/lseqtreeexampleB.tex}}
  \caption{\label{fig:lseqtreeexample} Example of \LSEQ's exponential trees with
    two antagonist editing behaviors to create the sequence of characters
    \texttt{QWERTY}. Contrarily to the example of
    Figure~\ref{fig:allocpathexample}, the depth of trees does not grow
    linearly.}
\end{figure}


Similarly to the example of Figure~\ref{fig:allocpathexample} the example given
in Figure~\ref{fig:lseqtreeexample} depicts the resulting trees after two
antagonist scenarios creating the sequence \texttt{QWERTY}
\begin{inparaenum}[(i)]
\item the left-to-right insertions sequence [($\texttt{Q},\,0$), ($\texttt{W},\,1$),
  \ldots] and
\item the right-to-left insertions sequence [($\texttt{Y},\,0$),
  ($\texttt{T},\,0$), \ldots].
\end{inparaenum}
In both cases, the exponential tree of \LSEQ starts with a maximum arity $2^5$
and doubles it at each level. Also, it uses the left-to-right and right-to-left
sub-allocation functions at the first and the second level of the tree
respectively. Since the first level of the tree uses the function designed for
left-to-right editing, the scenario involving the left-to-right editing sequence
results in a tree of depth 1. On the other hand -- and contrarily to the
allocation function presented in Figure~\ref{fig:allocpathexample} -- the
antagonist scenario only leads to a tree of depth 2. Indeed, the identifiers of
\LSEQ quickly reach a level of the tree where the sub-allocation function is
designed to handle the right-to-left editing behavior. If such editing behavior
continues, the new allocated paths will compensate the loss of the first level.

\subsection{Complexity analysis}
\label{subsec:complexity}

In text editing, most of the editing behaviors can be empirically summarized
as a composition of two basic editing behaviors.
\begin{inparaenum}[(i)]
\item The random editing behavior where the author inserts new elements at what
  appears random positions in the sequence. For instance, this behavior mostly
  arises when syntactic corrections are performed, e.g. the author writes
  \texttt{QWETY} and realizes that the \texttt{R} is missing. She adds the
  missing character in a second time.
\item The monotonic editing behavior where the author repeatedly inserts new
  elements between the last inserted element and an adjacent element (after or
  before exclusively). For instance, when an author writes \texttt{QWERTY}, she
  generally starts from the first character \texttt{Q} to the last letter of the
  word \texttt{Y}. On the opposite, insertions in a logfile are usually
  performed at the beginning for practical reasons. This behavior characterizes
  both left-to-right and right-to-left editing.
\end{inparaenum}

As a consequence, we focus on the space complexity analysis of \LSEQ to random
and monotonic editing behaviors to which we add a worst case complexity
analysis. It is worth noting that monotonic editing behavior represents an
unfavorable case since it tends to unbalance the underlying tree storing the
replicated sequence. As soon as the participants start to edit at different
positions -- which is closer from a real-life use case -- the tree becomes more
balanced and operations become more efficient proportionally. Also, the
analysis does not include an average case since it requires to know the average
distribution of the position of edits performed by a human collaborator which is
obviously very complex.

\subsubsection{Space complexity}

We distinguish the space complexity of each identifier from the space complexity
of the tree. The former being important since it directly impacts the
communication complexity, for that each identifier is broadcast to all
participants; The latter being important since it represents the replicated
document stored locally by each participant.

As stated in Section~\ref{subsec:lseqallocation}, paths require 1 additional bit
per concatenation. In turn, paths require $\mathcal{O}(e^2)$ bits to be encoded,
where $e$ is the depth of the element in the tree. Fortunately, the depth is
upper-bounded depending on the editing behavior that filled the exponential
tree.

The random editing behavior fills the tree at random. As a consequence, the tree
becomes balanced. Being exponential, the tree stores
$\textstyle\sum\nolimits_{i=1}^{k}{2^{(i^2-i)/2}}$ elements, where $k$ is the
depth of the tree. Thus, the depth of paths is upper-bounded by
$\mathcal{O}(\sqrt{\log I})$ concatenations, where $I$ is the number of
insertions. Since paths require $\mathcal{O}(e^2)$ bits to encode, paths have an
optimal logarithmic space complexity $\mathcal{O}(\log I)$. This result applies
to all variable-size identifier allocators~\cite{preguica2009commutative,
  weiss2009logoot}. However, since \LSEQ uses a tree structure factorizing
common parts of identifiers, the overall space complexity is not the sum of
identifiers but only $\mathcal{O}(I\log I)$.

The monotonic editing behavior fills only one branch of the tree. Yet, since the
maximum arity grows over depths, the tree tends to slow down its growth over
insertions. The tree stores up till $2^{e+1}-1$ elements, where $e$ is the depth
of the tree. Hence, the number of concatenation composing a path is
$\mathcal{O}(\log I)$, where $I$ is the number of insertions. Once again, since
the binary representation of paths increases quadratically, the space complexity
of paths taken individually is upper-bounded by $\mathcal{O}((\log I)^2)$.
Overall, the space complexity of the tree remains upper-bounded by
$\mathcal{O}(I\log I)$.

In the worst case, each insertion increases the depth of the tree. Thus, after
$I$ insertions, the tree comprises $e$ elements, where $e$ is the depth of the
tree. The space complexity of paths grows quadratically and each new allocated
path contains the full tree. Thus, the overall space complexity of the tree is
$\mathcal{O}(I^2)$ too.

\begin{table}
  \caption{\label{table:lseqspace}
    Upper bounds on space complexity of \LSEQ, Logoot and Treedoc. Where
    $I$ is the number of insertions performed on the replicated sequence.}
  \centering
  \input{input/lseqspacetable.tex}
\end{table}

Table~\ref{table:lseqspace} summarizes the space complexity of \LSEQ. In
particular, the expected growth of identifiers is bounded between an optimal
logarithm and a polylogarithm, hence, a sub-linear upper bound compared to the
number of insertions. To provide such improvement, \LSEQ sacrifices on its worst
case complexity that becomes quadratic. However, this worst case is made
difficult to produce, for the two sub-allocations functions with antagonist
designs settle each other's deficiency. Furthermore, if a malicious user tries
to produce the worst case, the difference in complexity makes it easy to detect,
hence, to handle. Table~\ref{table:lseqspace} also shows that compared to
state-of-the-art, \LSEQ significantly improves the identifiers size but exposes
a small overhead on the full structure, i.e. from $\mathcal{O}(I)$ to
$\mathcal{O}(I\log I)$. The tradeoff is beneficial since communications inherit
from the improvement.

\subsubsection{Time complexity}
\label{subsubsec:time}

Time complexity provides insights about the performance evolution of each
operation over insertions. They are divided between their local execution and
their remote integration.  Similarly to the space complexity, the analysis
focuses on three editing behaviors that filled the tree structure: random,
monotonic, and worst case.

The local insert operation simply consists in building a new path according to
two adjacent paths. Therefore, it depends of the depths of the latter which grow
depending on the editing behavior. Since the random, the monotonic, and the
worst case editing behaviors respectively lead to a depth growth upper-bounded
by $\mathcal{O}(\sqrt{\log I})$, $\mathcal{O}(\log I)$ and $\mathcal{O}(I)$, the
time complexity of the local part of the insert operation follows:
$\mathcal{O}(\sqrt{\log I})$, $\mathcal{O}(\log I)$ and $\mathcal{O}(I)$.

The local delete operation simply broadcasts the identifier of the element to
remove to all participants. Hence, whatever the editing behavior, the time
complexity is constant $\mathcal{O}(1)$.

Both the remote insert and delete operations perform the same instructions to
integrate the received result. Consequently, they have an identical time
complexity. Random, monotonic, and worst case editing behaviors respectively
lead to $\mathcal{O}(\sqrt{\log I})$, $\mathcal{O}(\log I)$ and $\mathcal{O}(I)$
levels in the exponential tree structure. Since children of each node are
ordered by path, we perform binary searches recursively until the right leaf is
found -- the delete operation removes the nodes it explores if and only if the
latter does not have at least another element inside its children. The
complexity of one binary search depends of the level $l$ at which it is
performed: $\mathcal{O}(\log 2^l)$. The repeated binary searches lead to an
upper bound of $\mathcal{O}(\textstyle\sum\nolimits_{i=1}^{e}(\log 2^i))$, where
$e$ is the depth of the tree. Replacing the depth $e$, upper bounds on time
complexity are $\mathcal{O}(\log I + \sqrt{log I})$,
$\mathcal{O}((\log I)^2+\log I)$, and $\mathcal{O}(I)$ for random, monotonic,
and worst case editing behaviors respectively. In the worst case, the algorithms
perform one comparison per element, i.e. per level, in the tree until they reach
the deepest leaf.


\begin{table}
  \caption{\label{table:lseqtime}
    Upper bounds on time complexity of \LSEQ. Where $I$ is the number of 
    insertions performed on the replicated sequence.}
  \centering
  \input{input/lseqtimetable.tex}
\end{table}

To interface the user's view of the document with the underlying replicated
sequence, an additional lookup operation is necessary. Its goal is to retrieve
the identifier of the element at the specified index in the sequence, and
converse. Since the structure is a tree, this access is not direct.

To consistently manage the translation between sequence structure and the tree
structure, the latter stores with each node the number of elements included in
its sub-trees. Each insertion and removal updates these counters as they explore
a path. Then, processing an index comes down to count the number of elements in
the siblings of explored nodes starting from the beginning or the end of the
sequence. Unfortunately, it can be costly depending on the editing behavior that
filled the tree.

The random editing behavior leads to an exponential tree of depth bounded by
$\mathcal{O}(\sqrt{\log I})$. In such a case, a very small portion of the whole
tree will be explored. The upper bound happens when the explored nodes are
exactly in the middle of its siblings, for it forces to check at least half of
these sibling per depth. Since each node stores twice as much children as its
parents. The number of siblings to check doubles at each depth. Overall, the sum
of these siblings is equal to the number of node at the deepest level, which is
$\mathcal{O}(2^{\sqrt{\log I}})$ elements. 

From an identical reasoning, the lookup operation after monotonic editing --
which also constitutes the worst case for this operation -- is upper-bounded by
$\mathcal{O}(I)$. Indeed, only one branch is filled and explored. The counters
become useless since all nodes but one have only one child. The exploration
directly ends up in the deepest level containing $\mathcal{O}(2^{\log_2 I})$
elements where half of them must be checked leading to
$\mathcal{O}(I)$.

\begin{table}
  \caption{\label{table:lseqlookup}
    Upper bounds on time complexity of the lookup on a \LSEQ structure.
    Where $I$ is the number of insertions performed on the replicated sequence.}
  \centering
  \input{input/lseqlookuptable.tex}
\end{table}

Table~\ref{table:lseqtime} and Table~\ref{table:lseqlookup} summarize the time
complexity of operations. The exponential tree structure leads to efficient
update operations. Its drawback lies in the lookup operation making the link
between the view and the replica. In particular, monotonic editing leads to the
worst case scenario where the access grows linearly. Fortunately,
\begin{inparaenum}[(i)]
\item the view should not be updated if the index of the change falls outside
  the user's visibility window. Thus, the lookup can stop earlier if it explores
  the tree outside the scope;
\item keeping fast accesses to the newest path and its adjacent paths removes
  the cost of the lookup, for the repeated insertions -- if monotonic -- alone
  can maintain these fast accesses up-to-date.
\end{inparaenum}

\subsubsection{Summary}

The complexity analysis reveals the improvements brought by \LSEQ as well as
their cost.  \LSEQ sacrifices on its worst case complexity to improve on other
editing behaviors that are considered more likely to happen in collaborative
editing. The most important result is the polylogarithmic space complexity of
identifiers, for it applies on communication complexity. In comparison,
state-of-the-art allocators~\cite{preguica2009commutative, weiss2009logoot} only
provided linearly upper-bounded identifiers. Other analysis such as the local
space consumed by the replicated structure, and the time complexity of provided
operations shows that the tree as replicated structure is
efficient. Nonetheless, based on preferences, one could choose an array -- as a
flat version of the tree -- to improve the performance of operations at the cost
of increased memory usage~\cite{weiss2009logoot}.  Section~\ref{sec:experiments}
validates our complexity analysis on experiments. The next section describes the
other components necessary to build a decentralized collaborative editor that
scales.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../paper"
%%% End: 