
\section{Introduction}

Google Docs made real-time editing in browsers easy for millions of users
(\REF). However, Google mediates real-time editing sessions with central servers
raising issues on privacy, censorship, and economic intelligence. It also raises
scalability issues in terms of the number of participants.  Despite that small
groups currently constitute the main range of users, events such as massive
online lectures, TV shows, conferences gather larger groups (\REF).  Google Docs
supports large groups but only the first fifty users can edit, next users have
their rights limited to document reading, not even in real-time.  We think that
real-time editors should allow editing at anytime and anywhere, whatever the
number of participants. Even if only a small subset among millions of
participants are writing, all participants of the editing session should be able
to read and write in real-time whenever they want.

Decentralized real-time editors~\cite{oster2006data, sun1998operational,
  sun2009contextbased} do not require intermediate servers and by the same
settle privacy issues. However, scalability issues remain.  Addressing
scalability requires finding a good trade-off between communication, space and
time complexities. Achieving a sublinear communication complexity compared to
the number of participants is crucial for supporting large groups.

To provide availability and responsiveness of documents, real-time editors use
optimistic replication~\cite{saito2005optimistic} of sequences, text documents
being sequences of characters. As such, each user manages a local copy of the
document and directly performs her modifications on it. Changes are broadcast to
all replica owners where they are integrated. The system is correct iff the
replicas integrating an identical set of operations converge to an equivalent
state, i.e., users read a same document~\cite{shapiro2011conflict}.

Decentralized algorithms of Operational
Transformation~\cite{sun2009contextbased} (OT) require piggybacking a state or a
context vector in order to detect concurrent operations. Unfortunately, state
vectors grow linearly with respect to the number of members that ever
participated in the authoring. Hence, these approaches are efficient for small
groups of users, but poorly scale to highly dynamic large groups of users and
high network latency.

Conflict-Free Replicated Data Types~\cite{shapiro2011comprehensive} (CRDTs) do
not pay the price of concurrency detection by providing commutative
operations. However, they require to piggyback unique and immutable identifiers
on every operation broadcast on the network. The size of this identifier is the
key for the communication complexity and consequently the scalability of the
approach. Two classes of CRDTs designed for sequences exist:
\begin{itemize}
\item CRDTs such as WOOT~\cite{oster2006data} piggyback a constant-size
  identifier which is optimal. However, it requires to keep tombstones, i.e., it
  marks elements as removed and hide them from the users. An empty document may
  store thousands of deleted elements. Tombstones degrade integration time of
  operations. This integration time blocks the user and eventually make the
  real-time editor unusable. Removing tombstones requires garbage
  collecting algorithms that do not scale.
\item CRDTs such as Logoot~\cite{weiss2010logootundo} do not require tombstones
  but piggyback variable-size identifiers. Depending on the identifier
  allocation strategy, the size of identifiers may grow linearly with the
  document size, increasing the communication cost. Balancing the structure
  requires consensus algorithms that do not scale.

  In previous works, we proposed an identifier allocation strategy called
  \LSEQ~\cite{nedelec2013concurrency, nedelec2013lseq}. It aims to avoid such
  balancing mechanism by sublinearly upper-bounding the space complexity of its
  identifiers. It is conjectured to have a polylogarithmic growth of the
  identifiers size $\mathcal{O}((\log d)^2)$ where $d$ \TODO{is the document
  size.}
\end{itemize}

\noindent The contributions of this paper are threefold:
\begin{itemize}
\item Compared to previous work~\cite{nedelec2013concurrency, nedelec2013lseq},
  we prove the upper bounds on space and time complexities of \LSEQ. This result
  opens the way for building decentralized and scalable real-time editors.
\item We ran extensive experiments characterizing \LSEQ's behavior that
  validates our analysis and compares with state-of-the-art approaches. Results
  show that \LSEQ scales better in terms of document size.
\item We describe all the outlines to develop a distributed collaborative editor
  for massive editing of large documents. Following these guidlines, we built a
  real-time decentralized editor running in web
  browsers\footnote{\url{https://github.com/Chat-Wane/CRATE}}. In the Grid'5000
  testbed, we launched editing sessions involving up till 600 connected
  browsers. The resulting documents reach millions of characters. It validates
  the scalability of the editor built on top of \LSEQ.
\end{itemize}

The remainder of this paper is organized as follows:
Section~\ref{sec:preliminaries} describes the necessary background to understand
the replicated data types for sequences. Section~\ref{sec:proposal} describes
the principle and functionning of \LSEQ. In particular, it provides its
complexity. Section~\ref{sec:editor} is about the decentralized real-time editor
built on top of \LSEQ. Experiments of Section~\ref{sec:experiments} highlights
its scalability while validating the complexity analysis.
Section~\ref{sec:conclusion} concludes.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../paper"
%%% End: 
